{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting my_dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile my_dataset.py\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class MyDataSet(Dataset):\n",
    "    \"\"\"自定义数据集\"\"\"\n",
    "\n",
    "    def __init__(self, images_path: list, images_class: list, transform=None):\n",
    "        self.images_path = images_path\n",
    "        self.images_class = images_class\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_path)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        img = Image.open(self.images_path[item]).convert('RGB')\n",
    "        # RGB为彩色图片，L为灰度图片\n",
    "        \n",
    "        label = self.images_class[item]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        # 官方实现的default_collate可以参考\n",
    "        # https://github.com/pytorch/pytorch/blob/67b7e751e6b5931a9f45274653f4f653a4e6cdf6/torch/utils/data/_utils/collate.py\n",
    "        images, labels = tuple(zip(*batch))\n",
    "\n",
    "        images = torch.stack(images, dim=0)\n",
    "        labels = torch.as_tensor(labels)\n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utils.py\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def read_split_data(root: str, val_rate: float = 0.2):\n",
    "    random.seed(0)  # 保证随机结果可复现\n",
    "    assert os.path.exists(root), \"dataset root: {} does not exist.\".format(root)\n",
    "\n",
    "    # 遍历文件夹，一个文件夹对应一个类别\n",
    "    flower_class = [cla for cla in os.listdir(root) if os.path.isdir(os.path.join(root, cla))]\n",
    "    # 排序，保证各平台顺序一致\n",
    "    flower_class.sort()\n",
    "    # 生成类别名称以及对应的数字索引\n",
    "    class_indices = dict((k, v) for v, k in enumerate(flower_class))\n",
    "    json_str = json.dumps(dict((val, key) for key, val in class_indices.items()), indent=4)\n",
    "    with open('class_indices.json', 'w') as json_file:\n",
    "        json_file.write(json_str)\n",
    "\n",
    "    train_images_path = []  # 存储训练集的所有图片路径\n",
    "    train_images_label = []  # 存储训练集图片对应索引信息\n",
    "    val_images_path = []  # 存储验证集的所有图片路径\n",
    "    val_images_label = []  # 存储验证集图片对应索引信息\n",
    "    every_class_num = []  # 存储每个类别的样本总数\n",
    "    supported = [\".jpg\", \".JPG\", \".png\", \".PNG\"]  # 支持的文件后缀类型\n",
    "    # 遍历每个文件夹下的文件\n",
    "    for cla in flower_class:\n",
    "        cla_path = os.path.join(root, cla)\n",
    "        # 遍历获取supported支持的所有文件路径\n",
    "        images = [os.path.join(root, cla, i) for i in os.listdir(cla_path)\n",
    "                  if os.path.splitext(i)[-1] in supported]\n",
    "        # 排序，保证各平台顺序一致\n",
    "        images.sort()\n",
    "        # 获取该类别对应的索引\n",
    "        image_class = class_indices[cla]\n",
    "        # 记录该类别的样本数量\n",
    "        every_class_num.append(len(images))\n",
    "        # 按比例随机采样验证样本\n",
    "        val_path = random.sample(images, k=int(len(images) * val_rate))\n",
    "\n",
    "        for img_path in images:\n",
    "            if img_path in val_path:  # 如果该路径在采样的验证集样本中则存入验证集\n",
    "                val_images_path.append(img_path)\n",
    "                val_images_label.append(image_class)\n",
    "            else:  # 否则存入训练集\n",
    "                train_images_path.append(img_path)\n",
    "                train_images_label.append(image_class)\n",
    "\n",
    "    print(\"{} images were found in the dataset.\".format(sum(every_class_num)))\n",
    "    print(\"{} images for training.\".format(len(train_images_path)))\n",
    "    print(\"{} images for validation.\".format(len(val_images_path)))\n",
    "    assert len(train_images_path) > 0, \"number of training images must greater than 0.\"\n",
    "    assert len(val_images_path) > 0, \"number of validation images must greater than 0.\"\n",
    "\n",
    "    plot_image = False\n",
    "    if plot_image:\n",
    "        # 绘制每种类别个数柱状图\n",
    "        plt.bar(range(len(flower_class)), every_class_num, align='center')\n",
    "        # 将横坐标0,1,2,3,4替换为相应的类别名称\n",
    "        plt.xticks(range(len(flower_class)), flower_class)\n",
    "        # 在柱状图上添加数值标签\n",
    "        for i, v in enumerate(every_class_num):\n",
    "            plt.text(x=i, y=v + 5, s=str(v), ha='center')\n",
    "        # 设置x坐标\n",
    "        plt.xlabel('image class')\n",
    "        # 设置y坐标\n",
    "        plt.ylabel('number of images')\n",
    "        # 设置柱状图的标题\n",
    "        plt.title('flower class distribution')\n",
    "        plt.show()\n",
    "\n",
    "    return train_images_path, train_images_label, val_images_path, val_images_label\n",
    "\n",
    "\n",
    "def plot_data_loader_image(data_loader):\n",
    "    batch_size = data_loader.batch_size\n",
    "    plot_num = min(batch_size, 4)\n",
    "\n",
    "    json_path = './class_indices.json'\n",
    "    assert os.path.exists(json_path), json_path + \" does not exist.\"\n",
    "    json_file = open(json_path, 'r')\n",
    "    class_indices = json.load(json_file)\n",
    "\n",
    "    for data in data_loader:\n",
    "        images, labels = data\n",
    "        for i in range(plot_num):\n",
    "            # [C, H, W] -> [H, W, C]\n",
    "            img = images[i].numpy().transpose(1, 2, 0)\n",
    "            # 反Normalize操作\n",
    "            img = (img * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406]) * 255\n",
    "            label = labels[i].item()\n",
    "            plt.subplot(1, plot_num, i+1)\n",
    "            plt.xlabel(class_indices[str(label)])\n",
    "            plt.xticks([])  # 去掉x轴的刻度\n",
    "            plt.yticks([])  # 去掉y轴的刻度\n",
    "            plt.imshow(img.astype('uint8'))\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def write_pickle(list_info: list, file_name: str):\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(list_info, f)\n",
    "\n",
    "\n",
    "def read_pickle(file_name: str) -> list:\n",
    "    with open(file_name, 'rb') as f:\n",
    "        info_list = pickle.load(f)\n",
    "        return info_list\n",
    "\n",
    "\n",
    "def train_one_epoch(model, optimizer, data_loader, device, epoch):\n",
    "    model.train()\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    accu_loss = torch.zeros(1).to(device)  # 累计损失\n",
    "    accu_num = torch.zeros(1).to(device)   # 累计预测正确的样本数\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    sample_num = 0\n",
    "    data_loader = tqdm(data_loader, file=sys.stdout)\n",
    "    for step, data in enumerate(data_loader):\n",
    "        images, labels = data\n",
    "        sample_num += images.shape[0]\n",
    "\n",
    "        pred = model(images.to(device))\n",
    "        pred_classes = torch.max(pred, dim=1)[1]\n",
    "        accu_num += torch.eq(pred_classes, labels.to(device)).sum()\n",
    "        labels = labels.to(device)\n",
    "        loss = loss_function(pred, labels)\n",
    "        loss.backward()\n",
    "        accu_loss += loss.detach()\n",
    "\n",
    "        data_loader.desc = \"[train epoch {}] loss: {:.3f}, acc: {:.3f}\".format(epoch,\n",
    "                                                                               accu_loss.item() / (step + 1),\n",
    "                                                                               accu_num.item() / sample_num)\n",
    "\n",
    "        if not torch.isfinite(loss):\n",
    "            print('WARNING: non-finite loss, ending training ', loss)\n",
    "            sys.exit(1)\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return accu_loss.item() / (step + 1), accu_num.item() / sample_num\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, data_loader, device, epoch):\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    accu_num = torch.zeros(1).to(device)   # 累计预测正确的样本数\n",
    "    accu_loss = torch.zeros(1).to(device)  # 累计损失\n",
    "\n",
    "    sample_num = 0\n",
    "    data_loader = tqdm(data_loader, file=sys.stdout)\n",
    "    for step, data in enumerate(data_loader):\n",
    "        images, labels = data\n",
    "        sample_num += images.shape[0]\n",
    "\n",
    "        pred = model(images.to(device))\n",
    "        pred_classes = torch.max(pred, dim=1)[1]\n",
    "        accu_num += torch.eq(pred_classes, labels.to(device)).sum()\n",
    "\n",
    "        loss = loss_function(pred, labels.to(device))\n",
    "        accu_loss += loss\n",
    "\n",
    "        data_loader.desc = \"[valid epoch {}] loss: {:.3f}, acc: {:.3f}\".format(epoch,\n",
    "                                                                               accu_loss.item() / (step + 1),\n",
    "                                                                               accu_num.item() / sample_num)\n",
    "\n",
    "    return accu_loss.item() / (step + 1), accu_num.item() / sample_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aimv2_1b_patch14_224',\n",
      " 'aimv2_1b_patch14_336',\n",
      " 'aimv2_1b_patch14_448',\n",
      " 'aimv2_3b_patch14_224',\n",
      " 'aimv2_3b_patch14_336',\n",
      " 'aimv2_3b_patch14_448',\n",
      " 'aimv2_huge_patch14_224',\n",
      " 'aimv2_huge_patch14_336',\n",
      " 'aimv2_huge_patch14_448',\n",
      " 'aimv2_large_patch14_224',\n",
      " 'aimv2_large_patch14_336',\n",
      " 'aimv2_large_patch14_448',\n",
      " 'bat_resnext26ts',\n",
      " 'beit_base_patch16_224',\n",
      " 'beit_base_patch16_384',\n",
      " 'beit_large_patch16_224',\n",
      " 'beit_large_patch16_384',\n",
      " 'beit_large_patch16_512',\n",
      " 'beitv2_base_patch16_224',\n",
      " 'beitv2_large_patch16_224',\n",
      " 'botnet26t_256',\n",
      " 'botnet50ts_256',\n",
      " 'caformer_b36',\n",
      " 'caformer_m36',\n",
      " 'caformer_s18',\n",
      " 'caformer_s36',\n",
      " 'cait_m36_384',\n",
      " 'cait_m48_448',\n",
      " 'cait_s24_224',\n",
      " 'cait_s24_384',\n",
      " 'cait_s36_384',\n",
      " 'cait_xs24_384',\n",
      " 'cait_xxs24_224',\n",
      " 'cait_xxs24_384',\n",
      " 'cait_xxs36_224',\n",
      " 'cait_xxs36_384',\n",
      " 'coat_lite_medium',\n",
      " 'coat_lite_medium_384',\n",
      " 'coat_lite_mini',\n",
      " 'coat_lite_small',\n",
      " 'coat_lite_tiny',\n",
      " 'coat_mini',\n",
      " 'coat_small',\n",
      " 'coat_tiny',\n",
      " 'coatnet_0_224',\n",
      " 'coatnet_0_rw_224',\n",
      " 'coatnet_1_224',\n",
      " 'coatnet_1_rw_224',\n",
      " 'coatnet_2_224',\n",
      " 'coatnet_2_rw_224',\n",
      " 'coatnet_3_224',\n",
      " 'coatnet_3_rw_224',\n",
      " 'coatnet_4_224',\n",
      " 'coatnet_5_224',\n",
      " 'coatnet_bn_0_rw_224',\n",
      " 'coatnet_nano_cc_224',\n",
      " 'coatnet_nano_rw_224',\n",
      " 'coatnet_pico_rw_224',\n",
      " 'coatnet_rmlp_0_rw_224',\n",
      " 'coatnet_rmlp_1_rw2_224',\n",
      " 'coatnet_rmlp_1_rw_224',\n",
      " 'coatnet_rmlp_2_rw_224',\n",
      " 'coatnet_rmlp_2_rw_384',\n",
      " 'coatnet_rmlp_3_rw_224',\n",
      " 'coatnet_rmlp_nano_rw_224',\n",
      " 'coatnext_nano_rw_224',\n",
      " 'convformer_b36',\n",
      " 'convformer_m36',\n",
      " 'convformer_s18',\n",
      " 'convformer_s36',\n",
      " 'convit_base',\n",
      " 'convit_small',\n",
      " 'convit_tiny',\n",
      " 'convmixer_768_32',\n",
      " 'convmixer_1024_20_ks9_p14',\n",
      " 'convmixer_1536_20',\n",
      " 'convnext_atto',\n",
      " 'convnext_atto_ols',\n",
      " 'convnext_atto_rms',\n",
      " 'convnext_base',\n",
      " 'convnext_femto',\n",
      " 'convnext_femto_ols',\n",
      " 'convnext_large',\n",
      " 'convnext_large_mlp',\n",
      " 'convnext_nano',\n",
      " 'convnext_nano_ols',\n",
      " 'convnext_pico',\n",
      " 'convnext_pico_ols',\n",
      " 'convnext_small',\n",
      " 'convnext_tiny',\n",
      " 'convnext_tiny_hnf',\n",
      " 'convnext_xlarge',\n",
      " 'convnext_xxlarge',\n",
      " 'convnext_zepto_rms',\n",
      " 'convnext_zepto_rms_ols',\n",
      " 'convnextv2_atto',\n",
      " 'convnextv2_base',\n",
      " 'convnextv2_femto',\n",
      " 'convnextv2_huge',\n",
      " 'convnextv2_large',\n",
      " 'convnextv2_nano',\n",
      " 'convnextv2_pico',\n",
      " 'convnextv2_small',\n",
      " 'convnextv2_tiny',\n",
      " 'crossvit_9_240',\n",
      " 'crossvit_9_dagger_240',\n",
      " 'crossvit_15_240',\n",
      " 'crossvit_15_dagger_240',\n",
      " 'crossvit_15_dagger_408',\n",
      " 'crossvit_18_240',\n",
      " 'crossvit_18_dagger_240',\n",
      " 'crossvit_18_dagger_408',\n",
      " 'crossvit_base_240',\n",
      " 'crossvit_small_240',\n",
      " 'crossvit_tiny_240',\n",
      " 'cs3darknet_focus_l',\n",
      " 'cs3darknet_focus_m',\n",
      " 'cs3darknet_focus_s',\n",
      " 'cs3darknet_focus_x',\n",
      " 'cs3darknet_l',\n",
      " 'cs3darknet_m',\n",
      " 'cs3darknet_s',\n",
      " 'cs3darknet_x',\n",
      " 'cs3edgenet_x',\n",
      " 'cs3se_edgenet_x',\n",
      " 'cs3sedarknet_l',\n",
      " 'cs3sedarknet_x',\n",
      " 'cs3sedarknet_xdw',\n",
      " 'cspdarknet53',\n",
      " 'cspresnet50',\n",
      " 'cspresnet50d',\n",
      " 'cspresnet50w',\n",
      " 'cspresnext50',\n",
      " 'darknet17',\n",
      " 'darknet21',\n",
      " 'darknet53',\n",
      " 'darknetaa53',\n",
      " 'davit_base',\n",
      " 'davit_base_fl',\n",
      " 'davit_giant',\n",
      " 'davit_huge',\n",
      " 'davit_huge_fl',\n",
      " 'davit_large',\n",
      " 'davit_small',\n",
      " 'davit_tiny',\n",
      " 'deit3_base_patch16_224',\n",
      " 'deit3_base_patch16_384',\n",
      " 'deit3_huge_patch14_224',\n",
      " 'deit3_large_patch16_224',\n",
      " 'deit3_large_patch16_384',\n",
      " 'deit3_medium_patch16_224',\n",
      " 'deit3_small_patch16_224',\n",
      " 'deit3_small_patch16_384',\n",
      " 'deit_base_distilled_patch16_224',\n",
      " 'deit_base_distilled_patch16_384',\n",
      " 'deit_base_patch16_224',\n",
      " 'deit_base_patch16_384',\n",
      " 'deit_small_distilled_patch16_224',\n",
      " 'deit_small_patch16_224',\n",
      " 'deit_tiny_distilled_patch16_224',\n",
      " 'deit_tiny_patch16_224',\n",
      " 'densenet121',\n",
      " 'densenet161',\n",
      " 'densenet169',\n",
      " 'densenet201',\n",
      " 'densenet264d',\n",
      " 'densenetblur121d',\n",
      " 'dla34',\n",
      " 'dla46_c',\n",
      " 'dla46x_c',\n",
      " 'dla60',\n",
      " 'dla60_res2net',\n",
      " 'dla60_res2next',\n",
      " 'dla60x',\n",
      " 'dla60x_c',\n",
      " 'dla102',\n",
      " 'dla102x',\n",
      " 'dla102x2',\n",
      " 'dla169',\n",
      " 'dm_nfnet_f0',\n",
      " 'dm_nfnet_f1',\n",
      " 'dm_nfnet_f2',\n",
      " 'dm_nfnet_f3',\n",
      " 'dm_nfnet_f4',\n",
      " 'dm_nfnet_f5',\n",
      " 'dm_nfnet_f6',\n",
      " 'dpn48b',\n",
      " 'dpn68',\n",
      " 'dpn68b',\n",
      " 'dpn92',\n",
      " 'dpn98',\n",
      " 'dpn107',\n",
      " 'dpn131',\n",
      " 'eca_botnext26ts_256',\n",
      " 'eca_halonext26ts',\n",
      " 'eca_nfnet_l0',\n",
      " 'eca_nfnet_l1',\n",
      " 'eca_nfnet_l2',\n",
      " 'eca_nfnet_l3',\n",
      " 'eca_resnet33ts',\n",
      " 'eca_resnext26ts',\n",
      " 'eca_vovnet39b',\n",
      " 'ecaresnet26t',\n",
      " 'ecaresnet50d',\n",
      " 'ecaresnet50d_pruned',\n",
      " 'ecaresnet50t',\n",
      " 'ecaresnet101d',\n",
      " 'ecaresnet101d_pruned',\n",
      " 'ecaresnet200d',\n",
      " 'ecaresnet269d',\n",
      " 'ecaresnetlight',\n",
      " 'ecaresnext26t_32x4d',\n",
      " 'ecaresnext50t_32x4d',\n",
      " 'edgenext_base',\n",
      " 'edgenext_small',\n",
      " 'edgenext_small_rw',\n",
      " 'edgenext_x_small',\n",
      " 'edgenext_xx_small',\n",
      " 'efficientformer_l1',\n",
      " 'efficientformer_l3',\n",
      " 'efficientformer_l7',\n",
      " 'efficientformerv2_l',\n",
      " 'efficientformerv2_s0',\n",
      " 'efficientformerv2_s1',\n",
      " 'efficientformerv2_s2',\n",
      " 'efficientnet_b0',\n",
      " 'efficientnet_b0_g8_gn',\n",
      " 'efficientnet_b0_g16_evos',\n",
      " 'efficientnet_b0_gn',\n",
      " 'efficientnet_b1',\n",
      " 'efficientnet_b1_pruned',\n",
      " 'efficientnet_b2',\n",
      " 'efficientnet_b2_pruned',\n",
      " 'efficientnet_b3',\n",
      " 'efficientnet_b3_g8_gn',\n",
      " 'efficientnet_b3_gn',\n",
      " 'efficientnet_b3_pruned',\n",
      " 'efficientnet_b4',\n",
      " 'efficientnet_b5',\n",
      " 'efficientnet_b6',\n",
      " 'efficientnet_b7',\n",
      " 'efficientnet_b8',\n",
      " 'efficientnet_blur_b0',\n",
      " 'efficientnet_cc_b0_4e',\n",
      " 'efficientnet_cc_b0_8e',\n",
      " 'efficientnet_cc_b1_8e',\n",
      " 'efficientnet_el',\n",
      " 'efficientnet_el_pruned',\n",
      " 'efficientnet_em',\n",
      " 'efficientnet_es',\n",
      " 'efficientnet_es_pruned',\n",
      " 'efficientnet_h_b5',\n",
      " 'efficientnet_l2',\n",
      " 'efficientnet_lite0',\n",
      " 'efficientnet_lite1',\n",
      " 'efficientnet_lite2',\n",
      " 'efficientnet_lite3',\n",
      " 'efficientnet_lite4',\n",
      " 'efficientnet_x_b3',\n",
      " 'efficientnet_x_b5',\n",
      " 'efficientnetv2_l',\n",
      " 'efficientnetv2_m',\n",
      " 'efficientnetv2_rw_m',\n",
      " 'efficientnetv2_rw_s',\n",
      " 'efficientnetv2_rw_t',\n",
      " 'efficientnetv2_s',\n",
      " 'efficientnetv2_xl',\n",
      " 'efficientvit_b0',\n",
      " 'efficientvit_b1',\n",
      " 'efficientvit_b2',\n",
      " 'efficientvit_b3',\n",
      " 'efficientvit_l1',\n",
      " 'efficientvit_l2',\n",
      " 'efficientvit_l3',\n",
      " 'efficientvit_m0',\n",
      " 'efficientvit_m1',\n",
      " 'efficientvit_m2',\n",
      " 'efficientvit_m3',\n",
      " 'efficientvit_m4',\n",
      " 'efficientvit_m5',\n",
      " 'ese_vovnet19b_dw',\n",
      " 'ese_vovnet19b_slim',\n",
      " 'ese_vovnet19b_slim_dw',\n",
      " 'ese_vovnet39b',\n",
      " 'ese_vovnet39b_evos',\n",
      " 'ese_vovnet57b',\n",
      " 'ese_vovnet99b',\n",
      " 'eva02_base_patch14_224',\n",
      " 'eva02_base_patch14_448',\n",
      " 'eva02_base_patch16_clip_224',\n",
      " 'eva02_enormous_patch14_clip_224',\n",
      " 'eva02_large_patch14_224',\n",
      " 'eva02_large_patch14_448',\n",
      " 'eva02_large_patch14_clip_224',\n",
      " 'eva02_large_patch14_clip_336',\n",
      " 'eva02_small_patch14_224',\n",
      " 'eva02_small_patch14_336',\n",
      " 'eva02_tiny_patch14_224',\n",
      " 'eva02_tiny_patch14_336',\n",
      " 'eva_giant_patch14_224',\n",
      " 'eva_giant_patch14_336',\n",
      " 'eva_giant_patch14_560',\n",
      " 'eva_giant_patch14_clip_224',\n",
      " 'eva_large_patch14_196',\n",
      " 'eva_large_patch14_336',\n",
      " 'fastvit_ma36',\n",
      " 'fastvit_mci0',\n",
      " 'fastvit_mci1',\n",
      " 'fastvit_mci2',\n",
      " 'fastvit_s12',\n",
      " 'fastvit_sa12',\n",
      " 'fastvit_sa24',\n",
      " 'fastvit_sa36',\n",
      " 'fastvit_t8',\n",
      " 'fastvit_t12',\n",
      " 'fbnetc_100',\n",
      " 'fbnetv3_b',\n",
      " 'fbnetv3_d',\n",
      " 'fbnetv3_g',\n",
      " 'flexivit_base',\n",
      " 'flexivit_large',\n",
      " 'flexivit_small',\n",
      " 'focalnet_base_lrf',\n",
      " 'focalnet_base_srf',\n",
      " 'focalnet_huge_fl3',\n",
      " 'focalnet_huge_fl4',\n",
      " 'focalnet_large_fl3',\n",
      " 'focalnet_large_fl4',\n",
      " 'focalnet_small_lrf',\n",
      " 'focalnet_small_srf',\n",
      " 'focalnet_tiny_lrf',\n",
      " 'focalnet_tiny_srf',\n",
      " 'focalnet_xlarge_fl3',\n",
      " 'focalnet_xlarge_fl4',\n",
      " 'gc_efficientnetv2_rw_t',\n",
      " 'gcresnet33ts',\n",
      " 'gcresnet50t',\n",
      " 'gcresnext26ts',\n",
      " 'gcresnext50ts',\n",
      " 'gcvit_base',\n",
      " 'gcvit_small',\n",
      " 'gcvit_tiny',\n",
      " 'gcvit_xtiny',\n",
      " 'gcvit_xxtiny',\n",
      " 'gernet_l',\n",
      " 'gernet_m',\n",
      " 'gernet_s',\n",
      " 'ghostnet_050',\n",
      " 'ghostnet_100',\n",
      " 'ghostnet_130',\n",
      " 'ghostnetv2_100',\n",
      " 'ghostnetv2_130',\n",
      " 'ghostnetv2_160',\n",
      " 'gmixer_12_224',\n",
      " 'gmixer_24_224',\n",
      " 'gmlp_b16_224',\n",
      " 'gmlp_s16_224',\n",
      " 'gmlp_ti16_224',\n",
      " 'halo2botnet50ts_256',\n",
      " 'halonet26t',\n",
      " 'halonet50ts',\n",
      " 'halonet_h1',\n",
      " 'haloregnetz_b',\n",
      " 'hardcorenas_a',\n",
      " 'hardcorenas_b',\n",
      " 'hardcorenas_c',\n",
      " 'hardcorenas_d',\n",
      " 'hardcorenas_e',\n",
      " 'hardcorenas_f',\n",
      " 'hgnet_base',\n",
      " 'hgnet_small',\n",
      " 'hgnet_tiny',\n",
      " 'hgnetv2_b0',\n",
      " 'hgnetv2_b1',\n",
      " 'hgnetv2_b2',\n",
      " 'hgnetv2_b3',\n",
      " 'hgnetv2_b4',\n",
      " 'hgnetv2_b5',\n",
      " 'hgnetv2_b6',\n",
      " 'hiera_base_224',\n",
      " 'hiera_base_abswin_256',\n",
      " 'hiera_base_plus_224',\n",
      " 'hiera_huge_224',\n",
      " 'hiera_large_224',\n",
      " 'hiera_small_224',\n",
      " 'hiera_small_abswin_256',\n",
      " 'hiera_tiny_224',\n",
      " 'hieradet_small',\n",
      " 'hrnet_w18',\n",
      " 'hrnet_w18_small',\n",
      " 'hrnet_w18_small_v2',\n",
      " 'hrnet_w18_ssld',\n",
      " 'hrnet_w30',\n",
      " 'hrnet_w32',\n",
      " 'hrnet_w40',\n",
      " 'hrnet_w44',\n",
      " 'hrnet_w48',\n",
      " 'hrnet_w48_ssld',\n",
      " 'hrnet_w64',\n",
      " 'inception_next_atto',\n",
      " 'inception_next_base',\n",
      " 'inception_next_small',\n",
      " 'inception_next_tiny',\n",
      " 'inception_resnet_v2',\n",
      " 'inception_v3',\n",
      " 'inception_v4',\n",
      " 'lambda_resnet26rpt_256',\n",
      " 'lambda_resnet26t',\n",
      " 'lambda_resnet50ts',\n",
      " 'lamhalobotnet50ts_256',\n",
      " 'lcnet_035',\n",
      " 'lcnet_050',\n",
      " 'lcnet_075',\n",
      " 'lcnet_100',\n",
      " 'lcnet_150',\n",
      " 'legacy_senet154',\n",
      " 'legacy_seresnet18',\n",
      " 'legacy_seresnet34',\n",
      " 'legacy_seresnet50',\n",
      " 'legacy_seresnet101',\n",
      " 'legacy_seresnet152',\n",
      " 'legacy_seresnext26_32x4d',\n",
      " 'legacy_seresnext50_32x4d',\n",
      " 'legacy_seresnext101_32x4d',\n",
      " 'legacy_xception',\n",
      " 'levit_128',\n",
      " 'levit_128s',\n",
      " 'levit_192',\n",
      " 'levit_256',\n",
      " 'levit_256d',\n",
      " 'levit_384',\n",
      " 'levit_384_s8',\n",
      " 'levit_512',\n",
      " 'levit_512_s8',\n",
      " 'levit_512d',\n",
      " 'levit_conv_128',\n",
      " 'levit_conv_128s',\n",
      " 'levit_conv_192',\n",
      " 'levit_conv_256',\n",
      " 'levit_conv_256d',\n",
      " 'levit_conv_384',\n",
      " 'levit_conv_384_s8',\n",
      " 'levit_conv_512',\n",
      " 'levit_conv_512_s8',\n",
      " 'levit_conv_512d',\n",
      " 'mambaout_base',\n",
      " 'mambaout_base_plus_rw',\n",
      " 'mambaout_base_short_rw',\n",
      " 'mambaout_base_tall_rw',\n",
      " 'mambaout_base_wide_rw',\n",
      " 'mambaout_femto',\n",
      " 'mambaout_kobe',\n",
      " 'mambaout_small',\n",
      " 'mambaout_small_rw',\n",
      " 'mambaout_tiny',\n",
      " 'maxvit_base_tf_224',\n",
      " 'maxvit_base_tf_384',\n",
      " 'maxvit_base_tf_512',\n",
      " 'maxvit_large_tf_224',\n",
      " 'maxvit_large_tf_384',\n",
      " 'maxvit_large_tf_512',\n",
      " 'maxvit_nano_rw_256',\n",
      " 'maxvit_pico_rw_256',\n",
      " 'maxvit_rmlp_base_rw_224',\n",
      " 'maxvit_rmlp_base_rw_384',\n",
      " 'maxvit_rmlp_nano_rw_256',\n",
      " 'maxvit_rmlp_pico_rw_256',\n",
      " 'maxvit_rmlp_small_rw_224',\n",
      " 'maxvit_rmlp_small_rw_256',\n",
      " 'maxvit_rmlp_tiny_rw_256',\n",
      " 'maxvit_small_tf_224',\n",
      " 'maxvit_small_tf_384',\n",
      " 'maxvit_small_tf_512',\n",
      " 'maxvit_tiny_pm_256',\n",
      " 'maxvit_tiny_rw_224',\n",
      " 'maxvit_tiny_rw_256',\n",
      " 'maxvit_tiny_tf_224',\n",
      " 'maxvit_tiny_tf_384',\n",
      " 'maxvit_tiny_tf_512',\n",
      " 'maxvit_xlarge_tf_224',\n",
      " 'maxvit_xlarge_tf_384',\n",
      " 'maxvit_xlarge_tf_512',\n",
      " 'maxxvit_rmlp_nano_rw_256',\n",
      " 'maxxvit_rmlp_small_rw_256',\n",
      " 'maxxvit_rmlp_tiny_rw_256',\n",
      " 'maxxvitv2_nano_rw_256',\n",
      " 'maxxvitv2_rmlp_base_rw_224',\n",
      " 'maxxvitv2_rmlp_base_rw_384',\n",
      " 'maxxvitv2_rmlp_large_rw_224',\n",
      " 'mixer_b16_224',\n",
      " 'mixer_b32_224',\n",
      " 'mixer_l16_224',\n",
      " 'mixer_l32_224',\n",
      " 'mixer_s16_224',\n",
      " 'mixer_s32_224',\n",
      " 'mixnet_l',\n",
      " 'mixnet_m',\n",
      " 'mixnet_s',\n",
      " 'mixnet_xl',\n",
      " 'mixnet_xxl',\n",
      " 'mnasnet_050',\n",
      " 'mnasnet_075',\n",
      " 'mnasnet_100',\n",
      " 'mnasnet_140',\n",
      " 'mnasnet_small',\n",
      " 'mobilenet_edgetpu_100',\n",
      " 'mobilenet_edgetpu_v2_l',\n",
      " 'mobilenet_edgetpu_v2_m',\n",
      " 'mobilenet_edgetpu_v2_s',\n",
      " 'mobilenet_edgetpu_v2_xs',\n",
      " 'mobilenetv1_100',\n",
      " 'mobilenetv1_100h',\n",
      " 'mobilenetv1_125',\n",
      " 'mobilenetv2_035',\n",
      " 'mobilenetv2_050',\n",
      " 'mobilenetv2_075',\n",
      " 'mobilenetv2_100',\n",
      " 'mobilenetv2_110d',\n",
      " 'mobilenetv2_120d',\n",
      " 'mobilenetv2_140',\n",
      " 'mobilenetv3_large_075',\n",
      " 'mobilenetv3_large_100',\n",
      " 'mobilenetv3_large_150d',\n",
      " 'mobilenetv3_rw',\n",
      " 'mobilenetv3_small_050',\n",
      " 'mobilenetv3_small_075',\n",
      " 'mobilenetv3_small_100',\n",
      " 'mobilenetv4_conv_aa_large',\n",
      " 'mobilenetv4_conv_aa_medium',\n",
      " 'mobilenetv4_conv_blur_medium',\n",
      " 'mobilenetv4_conv_large',\n",
      " 'mobilenetv4_conv_medium',\n",
      " 'mobilenetv4_conv_small',\n",
      " 'mobilenetv4_conv_small_035',\n",
      " 'mobilenetv4_conv_small_050',\n",
      " 'mobilenetv4_hybrid_large',\n",
      " 'mobilenetv4_hybrid_large_075',\n",
      " 'mobilenetv4_hybrid_medium',\n",
      " 'mobilenetv4_hybrid_medium_075',\n",
      " 'mobileone_s0',\n",
      " 'mobileone_s1',\n",
      " 'mobileone_s2',\n",
      " 'mobileone_s3',\n",
      " 'mobileone_s4',\n",
      " 'mobilevit_s',\n",
      " 'mobilevit_xs',\n",
      " 'mobilevit_xxs',\n",
      " 'mobilevitv2_050',\n",
      " 'mobilevitv2_075',\n",
      " 'mobilevitv2_100',\n",
      " 'mobilevitv2_125',\n",
      " 'mobilevitv2_150',\n",
      " 'mobilevitv2_175',\n",
      " 'mobilevitv2_200',\n",
      " 'mvitv2_base',\n",
      " 'mvitv2_base_cls',\n",
      " 'mvitv2_huge_cls',\n",
      " 'mvitv2_large',\n",
      " 'mvitv2_large_cls',\n",
      " 'mvitv2_small',\n",
      " 'mvitv2_small_cls',\n",
      " 'mvitv2_tiny',\n",
      " 'nasnetalarge',\n",
      " 'nest_base',\n",
      " 'nest_base_jx',\n",
      " 'nest_small',\n",
      " 'nest_small_jx',\n",
      " 'nest_tiny',\n",
      " 'nest_tiny_jx',\n",
      " 'nextvit_base',\n",
      " 'nextvit_large',\n",
      " 'nextvit_small',\n",
      " 'nf_ecaresnet26',\n",
      " 'nf_ecaresnet50',\n",
      " 'nf_ecaresnet101',\n",
      " 'nf_regnet_b0',\n",
      " 'nf_regnet_b1',\n",
      " 'nf_regnet_b2',\n",
      " 'nf_regnet_b3',\n",
      " 'nf_regnet_b4',\n",
      " 'nf_regnet_b5',\n",
      " 'nf_resnet26',\n",
      " 'nf_resnet50',\n",
      " 'nf_resnet101',\n",
      " 'nf_seresnet26',\n",
      " 'nf_seresnet50',\n",
      " 'nf_seresnet101',\n",
      " 'nfnet_f0',\n",
      " 'nfnet_f1',\n",
      " 'nfnet_f2',\n",
      " 'nfnet_f3',\n",
      " 'nfnet_f4',\n",
      " 'nfnet_f5',\n",
      " 'nfnet_f6',\n",
      " 'nfnet_f7',\n",
      " 'nfnet_l0',\n",
      " 'pit_b_224',\n",
      " 'pit_b_distilled_224',\n",
      " 'pit_s_224',\n",
      " 'pit_s_distilled_224',\n",
      " 'pit_ti_224',\n",
      " 'pit_ti_distilled_224',\n",
      " 'pit_xs_224',\n",
      " 'pit_xs_distilled_224',\n",
      " 'pnasnet5large',\n",
      " 'poolformer_m36',\n",
      " 'poolformer_m48',\n",
      " 'poolformer_s12',\n",
      " 'poolformer_s24',\n",
      " 'poolformer_s36',\n",
      " 'poolformerv2_m36',\n",
      " 'poolformerv2_m48',\n",
      " 'poolformerv2_s12',\n",
      " 'poolformerv2_s24',\n",
      " 'poolformerv2_s36',\n",
      " 'pvt_v2_b0',\n",
      " 'pvt_v2_b1',\n",
      " 'pvt_v2_b2',\n",
      " 'pvt_v2_b2_li',\n",
      " 'pvt_v2_b3',\n",
      " 'pvt_v2_b4',\n",
      " 'pvt_v2_b5',\n",
      " 'rdnet_base',\n",
      " 'rdnet_large',\n",
      " 'rdnet_small',\n",
      " 'rdnet_tiny',\n",
      " 'regnetv_040',\n",
      " 'regnetv_064',\n",
      " 'regnetx_002',\n",
      " 'regnetx_004',\n",
      " 'regnetx_004_tv',\n",
      " 'regnetx_006',\n",
      " 'regnetx_008',\n",
      " 'regnetx_016',\n",
      " 'regnetx_032',\n",
      " 'regnetx_040',\n",
      " 'regnetx_064',\n",
      " 'regnetx_080',\n",
      " 'regnetx_120',\n",
      " 'regnetx_160',\n",
      " 'regnetx_320',\n",
      " 'regnety_002',\n",
      " 'regnety_004',\n",
      " 'regnety_006',\n",
      " 'regnety_008',\n",
      " 'regnety_008_tv',\n",
      " 'regnety_016',\n",
      " 'regnety_032',\n",
      " 'regnety_040',\n",
      " 'regnety_040_sgn',\n",
      " 'regnety_064',\n",
      " 'regnety_080',\n",
      " 'regnety_080_tv',\n",
      " 'regnety_120',\n",
      " 'regnety_160',\n",
      " 'regnety_320',\n",
      " 'regnety_640',\n",
      " 'regnety_1280',\n",
      " 'regnety_2560',\n",
      " 'regnetz_005',\n",
      " 'regnetz_040',\n",
      " 'regnetz_040_h',\n",
      " 'regnetz_b16',\n",
      " 'regnetz_b16_evos',\n",
      " 'regnetz_c16',\n",
      " 'regnetz_c16_evos',\n",
      " 'regnetz_d8',\n",
      " 'regnetz_d8_evos',\n",
      " 'regnetz_d32',\n",
      " 'regnetz_e8',\n",
      " 'repghostnet_050',\n",
      " 'repghostnet_058',\n",
      " 'repghostnet_080',\n",
      " 'repghostnet_100',\n",
      " 'repghostnet_111',\n",
      " 'repghostnet_130',\n",
      " 'repghostnet_150',\n",
      " 'repghostnet_200',\n",
      " 'repvgg_a0',\n",
      " 'repvgg_a1',\n",
      " 'repvgg_a2',\n",
      " 'repvgg_b0',\n",
      " 'repvgg_b1',\n",
      " 'repvgg_b1g4',\n",
      " 'repvgg_b2',\n",
      " 'repvgg_b2g4',\n",
      " 'repvgg_b3',\n",
      " 'repvgg_b3g4',\n",
      " 'repvgg_d2se',\n",
      " 'repvit_m0_9',\n",
      " 'repvit_m1',\n",
      " 'repvit_m1_0',\n",
      " 'repvit_m1_1',\n",
      " 'repvit_m1_5',\n",
      " 'repvit_m2',\n",
      " 'repvit_m2_3',\n",
      " 'repvit_m3',\n",
      " 'res2net50_14w_8s',\n",
      " 'res2net50_26w_4s',\n",
      " 'res2net50_26w_6s',\n",
      " 'res2net50_26w_8s',\n",
      " 'res2net50_48w_2s',\n",
      " 'res2net50d',\n",
      " 'res2net101_26w_4s',\n",
      " 'res2net101d',\n",
      " 'res2next50',\n",
      " 'resmlp_12_224',\n",
      " 'resmlp_24_224',\n",
      " 'resmlp_36_224',\n",
      " 'resmlp_big_24_224',\n",
      " 'resnest14d',\n",
      " 'resnest26d',\n",
      " 'resnest50d',\n",
      " 'resnest50d_1s4x24d',\n",
      " 'resnest50d_4s2x40d',\n",
      " 'resnest101e',\n",
      " 'resnest200e',\n",
      " 'resnest269e',\n",
      " 'resnet10t',\n",
      " 'resnet14t',\n",
      " 'resnet18',\n",
      " 'resnet18d',\n",
      " 'resnet26',\n",
      " 'resnet26d',\n",
      " 'resnet26t',\n",
      " 'resnet32ts',\n",
      " 'resnet33ts',\n",
      " 'resnet34',\n",
      " 'resnet34d',\n",
      " 'resnet50',\n",
      " 'resnet50_clip',\n",
      " 'resnet50_clip_gap',\n",
      " 'resnet50_gn',\n",
      " 'resnet50_mlp',\n",
      " 'resnet50c',\n",
      " 'resnet50d',\n",
      " 'resnet50s',\n",
      " 'resnet50t',\n",
      " 'resnet50x4_clip',\n",
      " 'resnet50x4_clip_gap',\n",
      " 'resnet50x16_clip',\n",
      " 'resnet50x16_clip_gap',\n",
      " 'resnet50x64_clip',\n",
      " 'resnet50x64_clip_gap',\n",
      " 'resnet51q',\n",
      " 'resnet61q',\n",
      " 'resnet101',\n",
      " 'resnet101_clip',\n",
      " 'resnet101_clip_gap',\n",
      " 'resnet101c',\n",
      " 'resnet101d',\n",
      " 'resnet101s',\n",
      " 'resnet152',\n",
      " 'resnet152c',\n",
      " 'resnet152d',\n",
      " 'resnet152s',\n",
      " 'resnet200',\n",
      " 'resnet200d',\n",
      " 'resnetaa34d',\n",
      " 'resnetaa50',\n",
      " 'resnetaa50d',\n",
      " 'resnetaa101d',\n",
      " 'resnetblur18',\n",
      " 'resnetblur50',\n",
      " 'resnetblur50d',\n",
      " 'resnetblur101d',\n",
      " 'resnetrs50',\n",
      " 'resnetrs101',\n",
      " 'resnetrs152',\n",
      " 'resnetrs200',\n",
      " 'resnetrs270',\n",
      " 'resnetrs350',\n",
      " 'resnetrs420',\n",
      " 'resnetv2_18',\n",
      " 'resnetv2_18d',\n",
      " 'resnetv2_34',\n",
      " 'resnetv2_34d',\n",
      " 'resnetv2_50',\n",
      " 'resnetv2_50d',\n",
      " 'resnetv2_50d_evos',\n",
      " 'resnetv2_50d_frn',\n",
      " 'resnetv2_50d_gn',\n",
      " 'resnetv2_50t',\n",
      " 'resnetv2_50x1_bit',\n",
      " 'resnetv2_50x3_bit',\n",
      " 'resnetv2_101',\n",
      " 'resnetv2_101d',\n",
      " 'resnetv2_101x1_bit',\n",
      " 'resnetv2_101x3_bit',\n",
      " 'resnetv2_152',\n",
      " 'resnetv2_152d',\n",
      " 'resnetv2_152x2_bit',\n",
      " 'resnetv2_152x4_bit',\n",
      " 'resnext26ts',\n",
      " 'resnext50_32x4d',\n",
      " 'resnext50d_32x4d',\n",
      " 'resnext101_32x4d',\n",
      " 'resnext101_32x8d',\n",
      " 'resnext101_32x16d',\n",
      " 'resnext101_32x32d',\n",
      " 'resnext101_64x4d',\n",
      " 'rexnet_100',\n",
      " 'rexnet_130',\n",
      " 'rexnet_150',\n",
      " 'rexnet_200',\n",
      " 'rexnet_300',\n",
      " 'rexnetr_100',\n",
      " 'rexnetr_130',\n",
      " 'rexnetr_150',\n",
      " 'rexnetr_200',\n",
      " 'rexnetr_300',\n",
      " 'sam2_hiera_base_plus',\n",
      " 'sam2_hiera_large',\n",
      " 'sam2_hiera_small',\n",
      " 'sam2_hiera_tiny',\n",
      " 'samvit_base_patch16',\n",
      " 'samvit_base_patch16_224',\n",
      " 'samvit_huge_patch16',\n",
      " 'samvit_large_patch16',\n",
      " 'sebotnet33ts_256',\n",
      " 'sedarknet21',\n",
      " 'sehalonet33ts',\n",
      " 'selecsls42',\n",
      " 'selecsls42b',\n",
      " 'selecsls60',\n",
      " 'selecsls60b',\n",
      " 'selecsls84',\n",
      " 'semnasnet_050',\n",
      " 'semnasnet_075',\n",
      " 'semnasnet_100',\n",
      " 'semnasnet_140',\n",
      " 'senet154',\n",
      " 'sequencer2d_l',\n",
      " 'sequencer2d_m',\n",
      " 'sequencer2d_s',\n",
      " 'seresnet18',\n",
      " 'seresnet33ts',\n",
      " 'seresnet34',\n",
      " 'seresnet50',\n",
      " 'seresnet50t',\n",
      " 'seresnet101',\n",
      " 'seresnet152',\n",
      " 'seresnet152d',\n",
      " 'seresnet200d',\n",
      " 'seresnet269d',\n",
      " 'seresnetaa50d',\n",
      " 'seresnext26d_32x4d',\n",
      " 'seresnext26t_32x4d',\n",
      " 'seresnext26ts',\n",
      " 'seresnext50_32x4d',\n",
      " 'seresnext101_32x4d',\n",
      " 'seresnext101_32x8d',\n",
      " 'seresnext101_64x4d',\n",
      " 'seresnext101d_32x8d',\n",
      " 'seresnextaa101d_32x8d',\n",
      " 'seresnextaa201d_32x8d',\n",
      " 'skresnet18',\n",
      " 'skresnet34',\n",
      " 'skresnet50',\n",
      " 'skresnet50d',\n",
      " 'skresnext50_32x4d',\n",
      " 'spnasnet_100',\n",
      " 'swin_base_patch4_window7_224',\n",
      " 'swin_base_patch4_window12_384',\n",
      " 'swin_large_patch4_window7_224',\n",
      " 'swin_large_patch4_window12_384',\n",
      " 'swin_s3_base_224',\n",
      " 'swin_s3_small_224',\n",
      " 'swin_s3_tiny_224',\n",
      " 'swin_small_patch4_window7_224',\n",
      " 'swin_tiny_patch4_window7_224',\n",
      " 'swinv2_base_window8_256',\n",
      " 'swinv2_base_window12_192',\n",
      " 'swinv2_base_window12to16_192to256',\n",
      " 'swinv2_base_window12to24_192to384',\n",
      " 'swinv2_base_window16_256',\n",
      " 'swinv2_cr_base_224',\n",
      " 'swinv2_cr_base_384',\n",
      " 'swinv2_cr_base_ns_224',\n",
      " 'swinv2_cr_giant_224',\n",
      " 'swinv2_cr_giant_384',\n",
      " 'swinv2_cr_huge_224',\n",
      " 'swinv2_cr_huge_384',\n",
      " 'swinv2_cr_large_224',\n",
      " 'swinv2_cr_large_384',\n",
      " 'swinv2_cr_small_224',\n",
      " 'swinv2_cr_small_384',\n",
      " 'swinv2_cr_small_ns_224',\n",
      " 'swinv2_cr_small_ns_256',\n",
      " 'swinv2_cr_tiny_224',\n",
      " 'swinv2_cr_tiny_384',\n",
      " 'swinv2_cr_tiny_ns_224',\n",
      " 'swinv2_large_window12_192',\n",
      " 'swinv2_large_window12to16_192to256',\n",
      " 'swinv2_large_window12to24_192to384',\n",
      " 'swinv2_small_window8_256',\n",
      " 'swinv2_small_window16_256',\n",
      " 'swinv2_tiny_window8_256',\n",
      " 'swinv2_tiny_window16_256',\n",
      " 'test_byobnet',\n",
      " 'test_convnext',\n",
      " 'test_convnext2',\n",
      " 'test_convnext3',\n",
      " 'test_efficientnet',\n",
      " 'test_efficientnet_evos',\n",
      " 'test_efficientnet_gn',\n",
      " 'test_efficientnet_ln',\n",
      " 'test_mambaout',\n",
      " 'test_nfnet',\n",
      " 'test_resnet',\n",
      " 'test_vit',\n",
      " 'test_vit2',\n",
      " 'test_vit3',\n",
      " 'test_vit4',\n",
      " 'tf_efficientnet_b0',\n",
      " 'tf_efficientnet_b1',\n",
      " 'tf_efficientnet_b2',\n",
      " 'tf_efficientnet_b3',\n",
      " 'tf_efficientnet_b4',\n",
      " 'tf_efficientnet_b5',\n",
      " 'tf_efficientnet_b6',\n",
      " 'tf_efficientnet_b7',\n",
      " 'tf_efficientnet_b8',\n",
      " 'tf_efficientnet_cc_b0_4e',\n",
      " 'tf_efficientnet_cc_b0_8e',\n",
      " 'tf_efficientnet_cc_b1_8e',\n",
      " 'tf_efficientnet_el',\n",
      " 'tf_efficientnet_em',\n",
      " 'tf_efficientnet_es',\n",
      " 'tf_efficientnet_l2',\n",
      " 'tf_efficientnet_lite0',\n",
      " 'tf_efficientnet_lite1',\n",
      " 'tf_efficientnet_lite2',\n",
      " 'tf_efficientnet_lite3',\n",
      " 'tf_efficientnet_lite4',\n",
      " 'tf_efficientnetv2_b0',\n",
      " 'tf_efficientnetv2_b1',\n",
      " 'tf_efficientnetv2_b2',\n",
      " 'tf_efficientnetv2_b3',\n",
      " 'tf_efficientnetv2_l',\n",
      " 'tf_efficientnetv2_m',\n",
      " 'tf_efficientnetv2_s',\n",
      " 'tf_efficientnetv2_xl',\n",
      " 'tf_mixnet_l',\n",
      " 'tf_mixnet_m',\n",
      " 'tf_mixnet_s',\n",
      " 'tf_mobilenetv3_large_075',\n",
      " 'tf_mobilenetv3_large_100',\n",
      " 'tf_mobilenetv3_large_minimal_100',\n",
      " 'tf_mobilenetv3_small_075',\n",
      " 'tf_mobilenetv3_small_100',\n",
      " 'tf_mobilenetv3_small_minimal_100',\n",
      " 'tiny_vit_5m_224',\n",
      " 'tiny_vit_11m_224',\n",
      " 'tiny_vit_21m_224',\n",
      " 'tiny_vit_21m_384',\n",
      " 'tiny_vit_21m_512',\n",
      " 'tinynet_a',\n",
      " 'tinynet_b',\n",
      " 'tinynet_c',\n",
      " 'tinynet_d',\n",
      " 'tinynet_e',\n",
      " 'tnt_b_patch16_224',\n",
      " 'tnt_s_patch16_224',\n",
      " 'tresnet_l',\n",
      " 'tresnet_m',\n",
      " 'tresnet_v2_l',\n",
      " 'tresnet_xl',\n",
      " 'twins_pcpvt_base',\n",
      " 'twins_pcpvt_large',\n",
      " 'twins_pcpvt_small',\n",
      " 'twins_svt_base',\n",
      " 'twins_svt_large',\n",
      " 'twins_svt_small',\n",
      " 'vgg11',\n",
      " 'vgg11_bn',\n",
      " 'vgg13',\n",
      " 'vgg13_bn',\n",
      " 'vgg16',\n",
      " 'vgg16_bn',\n",
      " 'vgg19',\n",
      " 'vgg19_bn',\n",
      " 'visformer_small',\n",
      " 'visformer_tiny',\n",
      " 'vit_base_mci_224',\n",
      " 'vit_base_patch8_224',\n",
      " 'vit_base_patch14_dinov2',\n",
      " 'vit_base_patch14_reg4_dinov2',\n",
      " 'vit_base_patch16_18x2_224',\n",
      " 'vit_base_patch16_224',\n",
      " 'vit_base_patch16_224_miil',\n",
      " 'vit_base_patch16_384',\n",
      " 'vit_base_patch16_clip_224',\n",
      " 'vit_base_patch16_clip_384',\n",
      " 'vit_base_patch16_clip_quickgelu_224',\n",
      " 'vit_base_patch16_gap_224',\n",
      " 'vit_base_patch16_plus_240',\n",
      " 'vit_base_patch16_plus_clip_240',\n",
      " 'vit_base_patch16_reg4_gap_256',\n",
      " 'vit_base_patch16_rope_reg1_gap_256',\n",
      " 'vit_base_patch16_rpn_224',\n",
      " 'vit_base_patch16_siglip_224',\n",
      " 'vit_base_patch16_siglip_256',\n",
      " 'vit_base_patch16_siglip_384',\n",
      " 'vit_base_patch16_siglip_512',\n",
      " 'vit_base_patch16_siglip_gap_224',\n",
      " 'vit_base_patch16_siglip_gap_256',\n",
      " 'vit_base_patch16_siglip_gap_384',\n",
      " 'vit_base_patch16_siglip_gap_512',\n",
      " 'vit_base_patch16_xp_224',\n",
      " 'vit_base_patch32_224',\n",
      " 'vit_base_patch32_384',\n",
      " 'vit_base_patch32_clip_224',\n",
      " 'vit_base_patch32_clip_256',\n",
      " 'vit_base_patch32_clip_384',\n",
      " 'vit_base_patch32_clip_448',\n",
      " 'vit_base_patch32_clip_quickgelu_224',\n",
      " 'vit_base_patch32_plus_256',\n",
      " 'vit_base_r26_s32_224',\n",
      " 'vit_base_r50_s16_224',\n",
      " 'vit_base_r50_s16_384',\n",
      " 'vit_base_resnet26d_224',\n",
      " 'vit_base_resnet50d_224',\n",
      " 'vit_betwixt_patch16_gap_256',\n",
      " 'vit_betwixt_patch16_reg1_gap_256',\n",
      " 'vit_betwixt_patch16_reg4_gap_256',\n",
      " 'vit_betwixt_patch16_reg4_gap_384',\n",
      " 'vit_betwixt_patch16_rope_reg4_gap_256',\n",
      " 'vit_betwixt_patch32_clip_224',\n",
      " 'vit_giant_patch14_224',\n",
      " 'vit_giant_patch14_clip_224',\n",
      " 'vit_giant_patch14_dinov2',\n",
      " 'vit_giant_patch14_reg4_dinov2',\n",
      " 'vit_giant_patch16_gap_224',\n",
      " 'vit_gigantic_patch14_224',\n",
      " 'vit_gigantic_patch14_clip_224',\n",
      " 'vit_gigantic_patch14_clip_quickgelu_224',\n",
      " 'vit_huge_patch14_224',\n",
      " 'vit_huge_patch14_clip_224',\n",
      " 'vit_huge_patch14_clip_336',\n",
      " 'vit_huge_patch14_clip_378',\n",
      " 'vit_huge_patch14_clip_quickgelu_224',\n",
      " 'vit_huge_patch14_clip_quickgelu_378',\n",
      " 'vit_huge_patch14_gap_224',\n",
      " 'vit_huge_patch14_xp_224',\n",
      " 'vit_huge_patch16_gap_448',\n",
      " 'vit_intern300m_patch14_448',\n",
      " 'vit_large_patch14_224',\n",
      " 'vit_large_patch14_clip_224',\n",
      " 'vit_large_patch14_clip_336',\n",
      " 'vit_large_patch14_clip_quickgelu_224',\n",
      " 'vit_large_patch14_clip_quickgelu_336',\n",
      " 'vit_large_patch14_dinov2',\n",
      " 'vit_large_patch14_reg4_dinov2',\n",
      " 'vit_large_patch14_xp_224',\n",
      " 'vit_large_patch16_224',\n",
      " 'vit_large_patch16_384',\n",
      " 'vit_large_patch16_siglip_256',\n",
      " 'vit_large_patch16_siglip_384',\n",
      " 'vit_large_patch16_siglip_gap_256',\n",
      " 'vit_large_patch16_siglip_gap_384',\n",
      " 'vit_large_patch32_224',\n",
      " 'vit_large_patch32_384',\n",
      " 'vit_large_r50_s32_224',\n",
      " 'vit_large_r50_s32_384',\n",
      " 'vit_little_patch16_reg1_gap_256',\n",
      " 'vit_little_patch16_reg4_gap_256',\n",
      " 'vit_medium_patch16_clip_224',\n",
      " 'vit_medium_patch16_gap_240',\n",
      " 'vit_medium_patch16_gap_256',\n",
      " 'vit_medium_patch16_gap_384',\n",
      " 'vit_medium_patch16_reg1_gap_256',\n",
      " 'vit_medium_patch16_reg4_gap_256',\n",
      " 'vit_medium_patch16_rope_reg1_gap_256',\n",
      " 'vit_medium_patch32_clip_224',\n",
      " 'vit_mediumd_patch16_reg4_gap_256',\n",
      " 'vit_mediumd_patch16_reg4_gap_384',\n",
      " 'vit_mediumd_patch16_rope_reg1_gap_256',\n",
      " 'vit_pwee_patch16_reg1_gap_256',\n",
      " 'vit_relpos_base_patch16_224',\n",
      " 'vit_relpos_base_patch16_cls_224',\n",
      " 'vit_relpos_base_patch16_clsgap_224',\n",
      " 'vit_relpos_base_patch16_plus_240',\n",
      " 'vit_relpos_base_patch16_rpn_224',\n",
      " 'vit_relpos_base_patch32_plus_rpn_256',\n",
      " 'vit_relpos_medium_patch16_224',\n",
      " 'vit_relpos_medium_patch16_cls_224',\n",
      " 'vit_relpos_medium_patch16_rpn_224',\n",
      " 'vit_relpos_small_patch16_224',\n",
      " 'vit_relpos_small_patch16_rpn_224',\n",
      " 'vit_small_patch8_224',\n",
      " 'vit_small_patch14_dinov2',\n",
      " 'vit_small_patch14_reg4_dinov2',\n",
      " 'vit_small_patch16_18x2_224',\n",
      " 'vit_small_patch16_36x1_224',\n",
      " 'vit_small_patch16_224',\n",
      " 'vit_small_patch16_384',\n",
      " 'vit_small_patch32_224',\n",
      " 'vit_small_patch32_384',\n",
      " 'vit_small_r26_s32_224',\n",
      " 'vit_small_r26_s32_384',\n",
      " 'vit_small_resnet26d_224',\n",
      " 'vit_small_resnet50d_s16_224',\n",
      " 'vit_so150m2_patch16_reg1_gap_256',\n",
      " 'vit_so150m_patch16_reg4_gap_256',\n",
      " 'vit_so150m_patch16_reg4_gap_384',\n",
      " 'vit_so150m_patch16_reg4_map_256',\n",
      " 'vit_so400m_patch14_siglip_224',\n",
      " 'vit_so400m_patch14_siglip_378',\n",
      " 'vit_so400m_patch14_siglip_384',\n",
      " 'vit_so400m_patch14_siglip_gap_224',\n",
      " 'vit_so400m_patch14_siglip_gap_378',\n",
      " 'vit_so400m_patch14_siglip_gap_384',\n",
      " 'vit_so400m_patch14_siglip_gap_448',\n",
      " 'vit_so400m_patch14_siglip_gap_896',\n",
      " 'vit_so400m_patch16_siglip_256',\n",
      " 'vit_so400m_patch16_siglip_gap_256',\n",
      " 'vit_srelpos_medium_patch16_224',\n",
      " 'vit_srelpos_small_patch16_224',\n",
      " 'vit_tiny_patch16_224',\n",
      " 'vit_tiny_patch16_384',\n",
      " 'vit_tiny_r_s16_p8_224',\n",
      " 'vit_tiny_r_s16_p8_384',\n",
      " 'vit_wee_patch16_reg1_gap_256',\n",
      " 'vit_xsmall_patch16_clip_224',\n",
      " 'vitamin_base_224',\n",
      " 'vitamin_large2_224',\n",
      " 'vitamin_large2_256',\n",
      " 'vitamin_large2_336',\n",
      " 'vitamin_large2_384',\n",
      " 'vitamin_large_224',\n",
      " 'vitamin_large_256',\n",
      " 'vitamin_large_336',\n",
      " 'vitamin_large_384',\n",
      " 'vitamin_small_224',\n",
      " 'vitamin_xlarge_256',\n",
      " 'vitamin_xlarge_336',\n",
      " 'vitamin_xlarge_384',\n",
      " 'volo_d1_224',\n",
      " 'volo_d1_384',\n",
      " 'volo_d2_224',\n",
      " 'volo_d2_384',\n",
      " 'volo_d3_224',\n",
      " 'volo_d3_448',\n",
      " 'volo_d4_224',\n",
      " 'volo_d4_448',\n",
      " 'volo_d5_224',\n",
      " 'volo_d5_448',\n",
      " 'volo_d5_512',\n",
      " 'vovnet39a',\n",
      " 'vovnet57a',\n",
      " 'wide_resnet50_2',\n",
      " 'wide_resnet101_2',\n",
      " 'xception41',\n",
      " 'xception41p',\n",
      " 'xception65',\n",
      " 'xception65p',\n",
      " 'xception71',\n",
      " 'xcit_large_24_p8_224',\n",
      " 'xcit_large_24_p8_384',\n",
      " 'xcit_large_24_p16_224',\n",
      " 'xcit_large_24_p16_384',\n",
      " 'xcit_medium_24_p8_224',\n",
      " 'xcit_medium_24_p8_384',\n",
      " 'xcit_medium_24_p16_224',\n",
      " 'xcit_medium_24_p16_384',\n",
      " 'xcit_nano_12_p8_224',\n",
      " 'xcit_nano_12_p8_384',\n",
      " 'xcit_nano_12_p16_224',\n",
      " 'xcit_nano_12_p16_384',\n",
      " 'xcit_small_12_p8_224',\n",
      " 'xcit_small_12_p8_384',\n",
      " 'xcit_small_12_p16_224',\n",
      " 'xcit_small_12_p16_384',\n",
      " 'xcit_small_24_p8_224',\n",
      " 'xcit_small_24_p8_384',\n",
      " 'xcit_small_24_p16_224',\n",
      " 'xcit_small_24_p16_384',\n",
      " 'xcit_tiny_12_p8_224',\n",
      " 'xcit_tiny_12_p8_384',\n",
      " 'xcit_tiny_12_p16_224',\n",
      " 'xcit_tiny_12_p16_384',\n",
      " 'xcit_tiny_24_p8_224',\n",
      " 'xcit_tiny_24_p8_384',\n",
      " 'xcit_tiny_24_p16_224',\n",
      " 'xcit_tiny_24_p16_384']\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "from pprint import pprint\n",
    "model_names = timm.list_models()\n",
    "pprint(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "\n",
    "from my_dataset import MyDataSet\n",
    "#from model import swin_tiny_patch4_window7_224 as create_model\n",
    "from utils import read_split_data, train_one_epoch, evaluate\n",
    "import timm\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    device = torch.device(args.device if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    if os.path.exists(\"./weights\") is False:\n",
    "        os.makedirs(\"./weights\")\n",
    "\n",
    "    tb_writer = SummaryWriter()\n",
    "\n",
    "    train_images_path, train_images_label, val_images_path, val_images_label = read_split_data(args.data_path)\n",
    "\n",
    "    img_size = 224\n",
    "    data_transform = {\n",
    "        \"train\": transforms.Compose([transforms.RandomResizedCrop(img_size),\n",
    "                                     transforms.RandomHorizontalFlip(),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "        \"val\": transforms.Compose([transforms.Resize(int(img_size * 1.143)),\n",
    "                                   transforms.CenterCrop(img_size),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])}\n",
    "\n",
    "    # 实例化训练数据集\n",
    "    train_dataset = MyDataSet(images_path=train_images_path,\n",
    "                              images_class=train_images_label,\n",
    "                              transform=data_transform[\"train\"])\n",
    "\n",
    "    # 实例化验证数据集\n",
    "    val_dataset = MyDataSet(images_path=val_images_path,\n",
    "                            images_class=val_images_label,\n",
    "                            transform=data_transform[\"val\"])\n",
    "\n",
    "    batch_size = args.batch_size\n",
    "    nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers\n",
    "    print('Using {} dataloader workers every process'.format(nw))\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True,\n",
    "                                               pin_memory=True,\n",
    "                                               num_workers=nw,\n",
    "                                               collate_fn=train_dataset.collate_fn)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=False,\n",
    "                                             pin_memory=True,\n",
    "                                             num_workers=nw,\n",
    "                                             collate_fn=val_dataset.collate_fn)\n",
    "\n",
    "    #model = timm.create_model('deit_small_patch16_224', pretrained=True,num_classes=args.num_classes).to(device)\n",
    "    model = timm.create_model('convnext_small_in22k',pretrained=True,num_classes = args.num_classes).to(device)\n",
    "    if args.weights != \"\":\n",
    "        assert os.path.exists(args.weights), \"weights file: '{}' not exist.\".format(args.weights)\n",
    "        weights_dict = torch.load(args.weights, map_location=device)[\"model\"]\n",
    "        # 删除有关分类类别的权重\n",
    "        for k in list(weights_dict.keys()):\n",
    "            if \"head\" in k:\n",
    "                del weights_dict[k]\n",
    "        print(model.load_state_dict(weights_dict, strict=False))\n",
    "\n",
    "    if args.freeze_layers:\n",
    "        for name, para in model.named_parameters():\n",
    "            # 除head外，其他权重全部冻结\n",
    "            if \"head\" not in name:\n",
    "                para.requires_grad_(False)\n",
    "            else:\n",
    "                print(\"training {}\".format(name))\n",
    "\n",
    "    pg = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = optim.AdamW(pg, lr=args.lr, weight_decay=5E-2)\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        # train\n",
    "        train_loss, train_acc = train_one_epoch(model=model,\n",
    "                                                optimizer=optimizer,\n",
    "                                                data_loader=train_loader,\n",
    "                                                device=device,\n",
    "                                                epoch=epoch)\n",
    "\n",
    "        # validate\n",
    "        val_loss, val_acc = evaluate(model=model,\n",
    "                                     data_loader=val_loader,\n",
    "                                     device=device,\n",
    "                                     epoch=epoch)\n",
    "\n",
    "        tags = [\"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\", \"learning_rate\"]\n",
    "        tb_writer.add_scalar(tags[0], train_loss, epoch)\n",
    "        tb_writer.add_scalar(tags[1], train_acc, epoch)\n",
    "        tb_writer.add_scalar(tags[2], val_loss, epoch)\n",
    "        tb_writer.add_scalar(tags[3], val_acc, epoch)\n",
    "        tb_writer.add_scalar(tags[4], optimizer.param_groups[0][\"lr\"], epoch)\n",
    "\n",
    "        torch.save(model.state_dict(), \"./weights/model-{}.pth\".format(epoch))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--num_classes', type=int, default=5)\n",
    "    parser.add_argument('--epochs', type=int, default=10)\n",
    "    parser.add_argument('--batch-size', type=int, default=8)\n",
    "    parser.add_argument('--lr', type=float, default=0.0001)\n",
    "\n",
    "    # 数据集所在根目录\n",
    "    # https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
    "    parser.add_argument('--data-path', type=str,\n",
    "                        default=\"/data/flower_photos\")\n",
    "\n",
    "    # 预训练权重路径，如果不想载入就设置为空字符\n",
    "    parser.add_argument('--weights', type=str, default='',\n",
    "                        help='initial weights path')\n",
    "    # 是否冻结权重\n",
    "    parser.add_argument('--freeze-layers', type=bool, default=False)\n",
    "    parser.add_argument('--device', default='cuda:0', help='device id (i.e. 0 or 0,1 or cpu)')\n",
    "\n",
    "    opt = parser.parse_args()\n",
    "\n",
    "    main(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5400 images were found in the dataset.\n",
      "4320 images for training.\n",
      "1080 images for validation.\n",
      "Using 8 dataloader workers every process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leaper\\anaconda3\\envs\\pytorch\\lib\\site-packages\\timm\\models\\_factory.py:126: UserWarning: Mapping deprecated model name convnext_small_in22k to current convnext_small.fb_in22k.\n",
      "  model = create_fn(\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Leaper\\anaconda3\\envs\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 773, in urlopen\n",
      "    self._prepare_proxy(conn)\n",
      "  File \"c:\\Users\\Leaper\\anaconda3\\envs\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 1042, in _prepare_proxy\n",
      "    conn.connect()\n",
      "  File \"c:\\Users\\Leaper\\anaconda3\\envs\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 713, in connect\n",
      "    self.sock = sock = self._connect_tls_proxy(self.host, sock)\n",
      "  File \"c:\\Users\\Leaper\\anaconda3\\envs\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 813, in _connect_tls_proxy\n",
      "    sock_and_verified = _ssl_wrap_socket_and_match_hostname(\n",
      "  File \"c:\\Users\\Leaper\\anaconda3\\envs\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 920, in _ssl_wrap_socket_and_match_hostname\n",
      "    ssl_sock = ssl_wrap_socket(\n",
      "  File \"c:\\Users\\Leaper\\anaconda3\\envs\\pytorch\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 460, in ssl_wrap_socket\n",
      "    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)\n",
      "  File \"c:\\Users\\Leaper\\anaconda3\\envs\\pytorch\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 504, in _ssl_wrap_socket_impl\n",
      "    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\n",
      "  File \"c:\\Users\\Leaper\\anaconda3\\envs\\pytorch\\lib\\ssl.py\", line 500, in wrap_socket\n",
      "    return self.sslsocket_class._create(\n",
      "  File \"c:\\Users\\Leaper\\anaconda3\\envs\\pytorch\\lib\\ssl.py\", line 1040, in _create\n",
      "    self.do_handshake()\n",
      "  File \"c:\\Users\\Leaper\\anaconda3\\envs\\pytorch\\lib\\ssl.py\", line 1309, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "socket.timeout: _ssl.c:1105: The handshake operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Leaper\\anaconda3\\envs\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 775, in urlopen\n",
      "    self._raise_timeout(\n",
      "  File \"c:\\Users\\Leaper\\anaconda3\\envs\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 367, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "urllib3.exceptions.ProxyError: ('Unable to connect to proxy', ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Leaper\\anaconda3\\envs\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"c:\\Users\\Leaper\\anaconda3\\envs\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 841, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"c:\\Users\\Leaper\\anaconda3\\envs\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /timm/convnext_small.fb_in22k/resolve/main/model.safetensors (Caused by ProxyError('Unable to connect to proxy', ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\")))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\code_study\\ML_CODE\\kaggle\\Classfication\\Animal Image Dataset (90 Different Animals)\\ConvNext-small acc97.5%\\train.py\", line 130, in <module>\n",
      "    main(opt)\n",
      "  File \"d:\\code_study\\ML_CODE\\kaggle\\Classfication\\Animal Image Dataset (90 Different Animals)\\ConvNext-small acc97.5%\\train.py\", line 64, in main\n",
      "    model = timm.create_model('convnext_small_in22k',pretrained=True,num_classes = args.num_classes).to(device)\n",
      "  File \"c:\\Users\\Leaper\\anaconda3\\envs\\pytorch\\lib\\site-packages\\timm\\models\\_factory.py\", line 126, in create_model\n",
      "    model = create_fn(\n",
      "  File \"c:\\Users\\Leaper\\anaconda3\\envs\\pytorch\\lib\\site-packages\\timm\\models\\_registry.py\", line 145, in _fn\n",
      "    return current_fn(pretrained=pretrained, pretrained_cfg=pretrained_cfg or current_tag, **kwargs)\n",
      "  File \"c:\\Users\\Leaper\\anaconda3\\envs\\pytorch\\lib\\site-packages\\timm\\models\\convnext.py\", line 1107, in convnext_small\n",
      "    model = _create_convnext('convnext_small', pretrained=pretrained, **dict(model_args, **kwargs))\n",
      "  File \"c:\\Users\\Leaper\\anaconda3\\envs\\pytorch\\lib\\site-packages\\timm\\models\\convnext.py\", line 573, in _create_convnext\n",
      "    model = build_model_with_cfg(\n",
      "  File \"c:\\Users\\Leaper\\anaconda3\\envs\\pytorch\\lib\\site-packages\\timm\\models\\_builder.py\", line 436, in build_model_with_cfg\n",
      "    load_pretrained(\n",
      "  File \"c:\\Users\\Leaper\\anaconda3\\envs\\pytorch\\lib\\site-packages\\timm\\models\\_builder.py\", line 213, in load_pretrained\n",
      "    state_dict = load_state_dict_from_hf(pretrained_loc, weights_only=True, cache_dir=cache_dir)\n",
      "  File \"c:\\Users\\Leaper\\anaconda3\\envs\\pytorch\\lib\\site-packages\\timm\\models\\_hub.py\", line 211, in load_state_dict_from_hf\n",
      "    cached_safe_file = hf_hub_download(\n",
      "  File \"c:\\Users\\Leaper\\anaconda3\\envs\\pytorch\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\Leaper\\anaconda3\\envs\\pytorch\\lib\\site-packages\\huggingface_hub\\file_download.py\", line 860, in hf_hub_download\n",
      "    return _hf_hub_download_to_cache_dir(\n",
      "  File \"c:\\Users\\Leaper\\anaconda3\\envs\\pytorch\\lib\\site-packages\\huggingface_hub\\file_download.py\", line 923, in _hf_hub_download_to_cache_dir\n",
      "    (url_to_download, etag, commit_hash, expected_size, head_call_error) = _get_metadata_or_catch_error(\n",
      "  File \"c:\\Users\\Leaper\\anaconda3\\envs\\pytorch\\lib\\site-packages\\huggingface_hub\\file_download.py\", line 1374, in _get_metadata_or_catch_error\n",
      "    metadata = get_hf_file_metadata(\n",
      "  File \"c:\\Users\\Leaper\\anaconda3\\envs\\pytorch\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\Leaper\\anaconda3\\envs\\pytorch\\lib\\site-packages\\huggingface_hub\\file_download.py\", line 1294, in get_hf_file_metadata\n",
      "    r = _request_wrapper(\n",
      "  File \"c:\\Users\\Leaper\\anaconda3\\envs\\pytorch\\lib\\site-packages\\huggingface_hub\\file_download.py\", line 278, in _request_wrapper\n",
      "    response = _request_wrapper(\n",
      "  File \"c:\\Users\\Leaper\\anaconda3\\envs\\pytorch\\lib\\site-packages\\huggingface_hub\\file_download.py\", line 301, in _request_wrapper\n",
      "    response = get_session().request(method=method, url=url, **params)\n",
      "  File \"c:\\Users\\Leaper\\anaconda3\\envs\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\Users\\Leaper\\anaconda3\\envs\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\Users\\Leaper\\anaconda3\\envs\\pytorch\\lib\\site-packages\\huggingface_hub\\utils\\_http.py\", line 93, in send\n",
      "    return super().send(request, *args, **kwargs)\n",
      "  File \"c:\\Users\\Leaper\\anaconda3\\envs\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 694, in send\n",
      "    raise ProxyError(e, request=request)\n",
      "requests.exceptions.ProxyError: (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /timm/convnext_small.fb_in22k/resolve/main/model.safetensors (Caused by ProxyError(\\'Unable to connect to proxy\\', ReadTimeoutError(\"HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Read timed out. (read timeout=10)\")))'), '(Request ID: 857689d2-f1da-48f1-bca0-f6a365f76877)')\n"
     ]
    }
   ],
   "source": [
    "!python train.py --data-path D:/code_study/ML_CODE/dataSets/Classification/Animal_Image_Dataset_90DifferentAnimals/animals/animals --num_classes 90 --epochs 20 --batch-size 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
